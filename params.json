{
  "name": "End-to-end Provenance",
  "tagline": "",
  "body": "Technology continues to change the way that scientists work. Nearly all scientific data are analyzed with computers and increasingly data are collected directly in electronic form. A good example is provided by sensor networks, which may utilize electronic sensors and wireless networks to collect vast quantities of data at very fast rates. Scientific programs, ranging from Excel spreadsheets to supercomputer applications, manipulate the collected data to produce scientific results. Scientists can then disseminate both the raw and processed data quickly and to a broad, unknown audience by publishing it on their websites.\r\n\r\nGood science requires more than results. It requires reproducibility, verifiability and authentication. Reproducibility is necessary to ensure that the results are not an accidental outcome, but the result of genuine, carefully-performed experimentation and analysis. Verifiability is necessary to assure that the results really did derive from the data, even if reproducing the experiment is not a viable option. Finally, authentication is necessary to believe that the raw data used in the scientific work is itself valid. Without confidence in these issues, the credibility of data posted on the Internet has the same level as the typical Wikipedia article.\r\n\r\nFor example, data may be collected by sensors and downloaded to a computer, perhaps run through some scripts to perform calibration and cleaning, posting the results for public use on a website, without a scientist checking their validity. What can go wrong? An anemometer might freeze in an icestorm, reporting a windspeed of 0 incorrectly. A sensor might slip out of calibration over time, but the amount of slippage will remain unknown until the sensor is shipped back to the manufacturer for calibration tests, most likely long after the data have been made publicly available. And so on. With the pace at which sensors produce data and programs manipulate data, it is clear that documentation of the data's provenance itself must be automated, so that there can be some hope of understanding the data and correcting for errors that arise in its collection or handling.\r\n\r\n### Resources\r\n* [RDataTracker](https://github.com/blernermhc/RDataTracker)\r\n* [DDG](https://github.com/blernermhc/ddg)\r\n* [Core Provenance Library](https://github.com/pmacko86/core-provenance-library)\r\n\r\n### Authors and Contributors\r\n* Aaron Ellison (@amellison17) [website](http://harvardforest.fas.harvard.edu/aaron-ellison)\r\n* Barbara Staudt Lerner (@blernermhc) [website](https://www.mtholyoke.edu/~blerner/)\r\n* Emery Boose (@erboose) [website](http://harvardforest.fas.harvard.edu/researchers/9)\r\n* Margo Seltzer (@margoseltzer) [website](https://www.eecs.harvard.edu/margo/)\r\n* Matthew Lau (@MKLau) [website](http://harvardforest.fas.harvard.edu/researchers/8438)\r\n* Thomas Pasquier (@tfjmp) [website](http://www.cl.cam.ac.uk/~tfjmp2/)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}